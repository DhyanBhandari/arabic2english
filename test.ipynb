{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     eng  \\\n",
       "0                                                    Hi.   \n",
       "1                                                   Run!   \n",
       "2                                                  Help!   \n",
       "3                                                  Jump!   \n",
       "4                                                  Stop!   \n",
       "...                                                  ...   \n",
       "24633  rising voices promoting a more linguistically ...   \n",
       "24634  following last year s successful campaign we i...   \n",
       "24635  during last year s challenge we also met langu...   \n",
       "24636  to take part just follow the simple steps outl...   \n",
       "24637  you will also find links to some free web base...   \n",
       "\n",
       "                                                      ar  \n",
       "0                                                مرحبًا.  \n",
       "1                                                  اركض!  \n",
       "2                                                النجدة!  \n",
       "3                                                  اقفز!  \n",
       "4                                                    قف!  \n",
       "...                                                  ...  \n",
       "24633  شاركنا تحدي ابداع ميم بلغتك الام تعزيزا للتنوع...  \n",
       "24634  استكمالا لنجاح حملة العام السابق ندعوكم للمشار...  \n",
       "24635  تعرفنا خلال تحدي العام الماضي على ابطال لغويين...  \n",
       "24636  للمشاركة في التحدي اتبع الخطوات الموضحة على ال...  \n",
       "24637  ستجد ايضا روابط لمجموعة من منصات ابداع الميم ا...  \n",
       "\n",
       "[24638 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eng</th>\n      <th>ar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>مرحبًا.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>اركض!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Help!</td>\n      <td>النجدة!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump!</td>\n      <td>اقفز!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stop!</td>\n      <td>قف!</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24633</th>\n      <td>rising voices promoting a more linguistically ...</td>\n      <td>شاركنا تحدي ابداع ميم بلغتك الام تعزيزا للتنوع...</td>\n    </tr>\n    <tr>\n      <th>24634</th>\n      <td>following last year s successful campaign we i...</td>\n      <td>استكمالا لنجاح حملة العام السابق ندعوكم للمشار...</td>\n    </tr>\n    <tr>\n      <th>24635</th>\n      <td>during last year s challenge we also met langu...</td>\n      <td>تعرفنا خلال تحدي العام الماضي على ابطال لغويين...</td>\n    </tr>\n    <tr>\n      <th>24636</th>\n      <td>to take part just follow the simple steps outl...</td>\n      <td>للمشاركة في التحدي اتبع الخطوات الموضحة على ال...</td>\n    </tr>\n    <tr>\n      <th>24637</th>\n      <td>you will also find links to some free web base...</td>\n      <td>ستجد ايضا روابط لمجموعة من منصات ابداع الميم ا...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24638 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torch.nn  import functional as F\n",
    "import torch.optim as  optim \n",
    "df = pd.read_csv(\"data/arabic_english.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.25.1)2021-06-22 14:53:06.571861: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n",
      "\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.60.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.21.0rc2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.5.30)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "source": [
    "# Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('في', 10114), ('من', 8806), ('على', 5213), ('ان', 2562), ('عن', 2299), ('العالمية', 2260), ('الاصوات', 2191), ('الى', 1867), ('لا', 1599), ('هذا', 1572), ('ما', 1385), ('التي', 1384), ('هذه', 1157), ('مع', 1077), ('الذي', 847), ('أن', 824), ('ذلك', 808), ('كان', 799), ('لم', 797), ('او', 797), ('الانترنت', 785), ('توم', 733), ('هل', 715), ('و', 715), ('كل', 671), ('بعد', 668), ('هو', 616), ('قبل', 580), ('تم', 572), ('موقع', 562), ('حول', 552), ('عام', 505), ('العالم', 496), ('حيث', 488), ('كما', 485), ('بين', 463), ('اكثر', 448), ('المدون', 447), ('قد', 445), ('غير', 441), ('خلال', 432), ('أنا', 432), ('إلى', 428), ('يوم', 427), ('هناك', 426), ('كانت', 424), ('بعض', 420), ('ايضا', 419), ('هي', 419), ('اي', 418)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ar import Arabic\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "df = pd.read_csv(\"data/arabic_english.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "\n",
    "'''\n",
    "First :\n",
    "python -m spacy download en_core_web_sm\n",
    "'''\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "arab = Arabic()\n",
    "ar_Tokenizer = Tokenizer(arab.vocab)\n",
    "\n",
    "def engTokenizer(text):\n",
    " return  [word.text for word in spacy_eng.tokenizer(text)] \n",
    "\n",
    "def arTokenizer(sentence):\n",
    "    return  [word.text for word in \n",
    "             ar_Tokenizer(re.sub(r\"\\s+\",\" \",re.sub(r\"[\\.\\'\\\"\\n+]\",\" \",sentence)).strip())]\n",
    "\n",
    "SRC = data.Field(tokenize=engTokenizer,batch_first=False,init_token=\"<sos>\",eos_token=\"<eos>\")\n",
    "TARGET = data.Field(tokenize=arTokenizer,batch_first=False,tokenizer_language=\"ar\",init_token=\"ببدأ\",eos_token=\"نهها\")\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, src_field, target_field, is_test=False, **kwargs):\n",
    "        fields = [('eng', src_field), ('ar',target_field)]\n",
    "        samples = []\n",
    "        for i, row in df.iterrows():\n",
    "            eng = row.eng \n",
    "            ar = row.ar\n",
    "            samples.append(data.Example.fromlist([eng, ar], fields))\n",
    "\n",
    "        super().__init__(samples, fields, **kwargs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "torchdataset = TextDataset(df,SRC,TARGET)\n",
    "\n",
    "train_data, valid_data = torchdataset.split(split_ratio=0.8, random_state = random.seed(0))\n",
    "\n",
    "SRC.build_vocab(train_data,min_freq=2)\n",
    "TARGET.build_vocab(train_data,min_freq=2)\n",
    "\n",
    "print(TARGET.vocab.freqs.most_common(50))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_embeddings = nn.Embedding(src_vocab_size,embedding_size)\n",
    "        self.src_positional_embeddings= nn.Embedding(max_len,embedding_size)\n",
    "        self.trg_embeddings= nn.Embedding(trg_vocab_size,embedding_size)\n",
    "        self.trg_positional_embeddings= nn.Embedding(max_len,embedding_size)\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0,1) == self.src_pad_idx\n",
    "\n",
    "        return src_mask\n",
    "\n",
    "    def forward(self,src,trg):\n",
    "        src_seq_length, S = src.shape\n",
    "        trg_seq_length, S = trg.shape\n",
    "        #adding zeros is an easy way\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length).unsqueeze(1).expand(src_seq_length, S).to(self.device)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length, S).to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src  = self.dropout(\n",
    "                ( self.src_embeddings(src) + self.src_positional_embeddings(src_positions) )\n",
    "            )\n",
    "\n",
    "        embed_trg = self.dropout(\n",
    "                ( self.trg_embeddings(trg) + self.trg_positional_embeddings(trg_positions) )\n",
    "            )\n",
    "        \n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(device)\n",
    "        \n",
    "        \n",
    "        out = self.transformer(embed_src,embed_trg, src_key_padding_mask=src_padding_mask,tgt_mask=trg_mask )\n",
    "        out= self.fc_out(out)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "source": [
    "# Training phase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "train_iterator, valid_iterator  = data.BucketIterator.splits(\n",
    "    (train_data,valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort=None,\n",
    "    sort_within_batch=False,\n",
    "    sort_key = lambda x: len(x.SRC),\n",
    "    shuffle=None, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of english vocabulary: 12886\nSize of arabic vocabulary: 22062\n"
     ]
    }
   ],
   "source": [
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "num_epochs = 60\n",
    "learning_rate = 3e-4\n",
    "\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "max_len= 250\n",
    "dropout = 0.10\n",
    "embedding_size= 512\n",
    "src_pad_idx = SRC.vocab.stoi[\"<pad>\"]\n",
    "forward_expansion = 4\n",
    "step = 0\n",
    "\n",
    "\n",
    "src_vocab_size  = len(SRC.vocab)\n",
    "print(\"Size of english vocabulary:\",src_vocab_size)\n",
    "\n",
    "#No. of unique tokens in label\n",
    "trg_vocab_size =len(TARGET.vocab)\n",
    "print(\"Size of arabic vocabulary:\",trg_vocab_size)\n",
    "\n",
    "\n",
    "model = Transformer(        \n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n        [ 2121,     0,   232,  ...,     0,  2709,    15],\n        [  224,  1377,  2451,  ...,    31, 11479,   221],\n        ...,\n        [    1,     1,     1,  ...,     1,     1,     1],\n        [    1,     1,     1,  ...,     1,     1,     1],\n        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')\n<class 'torchtext.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "for i,batch  in enumerate(train_iterator):\n",
    "    print(batch.eng)\n",
    "    print(type(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 970.00 MiB (GPU 0; 8.00 GiB total capacity; 5.13 GiB already allocated; 150.07 MiB free; 5.79 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-b8670c2a32f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m-> 1121\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2824\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 970.00 MiB (GPU 0; 8.00 GiB total capacity; 5.13 GiB already allocated; 150.07 MiB free; 5.79 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "loss_validation_track= []\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = SRC.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    stepLoss=[]\n",
    "    model.train()\n",
    "    for i,batch  in enumerate(train_iterator):\n",
    "        input_data = batch.eng.to(device)\n",
    "        target = batch.ar.to(device)\n",
    "\n",
    "        output = model(input_data,target[:-1])\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = output.reshape(-1,trg_vocab_size)\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        stepLoss.append(loss.item())\n",
    "\n",
    "    loss_track.append(np.mean(stepLoss))\n",
    "    print(\"train crossentropy at epoch {} loss: \".format(i),np.mean(stepLoss))        \n",
    "        \n",
    "    stepValidLoss=[]\n",
    "    model.eval() # the evaluation mode for the model (doesn't apply dropout and batchNorm)\n",
    "    for i,batch  in enumerate(valid_iterator):\n",
    "            input_sentence = batch.eng.to(device)\n",
    "            target = batch.ar.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_sentence,trg[:-1])\n",
    "            output = output.reshape(-1,trg_vocab_size)\n",
    "            target = target[1:].reshape(-1)\n",
    "            loss = criterion(output,target)\n",
    "                \n",
    "            stepValidLoss.append(loss.item())\n",
    "  \n",
    "loss_validation_track.append(np.mean(stepValidLoss))\n",
    "print(\"validation crossentropy at epoch {} loss: \".format(i),np.mean(stepValidLoss))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "fd81d4bbdfde70f601f6d77fb70c4bb77f9bd45bc2d5b01219f46a743c5582e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}