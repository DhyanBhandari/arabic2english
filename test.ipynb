{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n",
      "\n",
      "Building graph of deps:   0%|          | 0/7 [00:00<?, ?it/s]\n",
      "Examining pytorch:   0%|          | 0/7 [00:00<?, ?it/s]     \n",
      "Examining python=3.7:  14%|█▍        | 1/7 [00:00<00:04,  1.43it/s]\n",
      "Examining python=3.7:  29%|██▊       | 2/7 [00:00<00:01,  2.85it/s]\n",
      "Examining cudatoolkit=11:  29%|██▊       | 2/7 [00:00<00:01,  2.85it/s]\n",
      "Examining cudatoolkit=11:  43%|████▎     | 3/7 [00:00<00:01,  3.59it/s]\n",
      "Examining @/win-64::__archspec==1=x86_64:  43%|████▎     | 3/7 [00:00<00:01,  3.59it/s]\n",
      "Examining torchvision:  57%|█████▋    | 4/7 [00:00<00:00,  3.59it/s]                   \n",
      "Examining @/win-64::__win==0=0:  71%|███████▏  | 5/7 [00:01<00:00,  3.59it/s]\n",
      "Examining @/win-64::__win==0=0:  86%|████████▌ | 6/7 [00:01<00:00,  4.21it/s]\n",
      "Examining @/win-64::__cuda==11.3=0:  86%|████████▌ | 6/7 [00:01<00:00,  4.21it/s]\n",
      "                                                                                 \n",
      "\n",
      "Determining conflicts:   0%|          | 0/7 [00:00<?, ?it/s]\n",
      "Examining conflict for pytorch torchvision:   0%|          | 0/7 [00:00<?, ?it/s]\n",
      "Examining conflict for pytorch python torchvision:  14%|█▍        | 1/7 [00:00<00:00, 10.26it/s]\n",
      "Examining conflict for pytorch python cudatoolkit torchvision:  29%|██▊       | 2/7 [00:00<00:00, 10.34it/s]\n",
      "Examining conflict for pytorch python cudatoolkit torchvision:  43%|████▎     | 3/7 [00:00<00:00, 15.50it/s]\n",
      "Examining conflict for pytorch cudatoolkit torchvision:  43%|████▎     | 3/7 [00:00<00:00, 15.50it/s]       \n",
      "Examining conflict for pytorch cudatoolkit torchvision:  57%|█████▋    | 4/7 [00:00<00:00,  5.30it/s]\n",
      "Examining conflict for python torchvision:  57%|█████▋    | 4/7 [00:00<00:00,  5.30it/s]             \n",
      "                                                                                        \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - torchvision -> python[version='>=2.7,<2.8.0a0|>=3.5,<3.6.0a0']\n",
      "\n",
      "Your python: python=3.7\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "The following specifications were found to be incompatible with each other:\n",
      "\n",
      "Output in format: Requested package -> Available versions\n",
      "\n",
      "Package cudatoolkit conflicts for:\n",
      "torchvision -> pytorch==1.8.0.dev20210208 -> cudatoolkit[version='>=11.0,<11.0.221']\n",
      "torchvision -> cudatoolkit[version='>=10.1,<10.2|>=10.2,<10.3|>=11.1,<11.2|>=11.2,<11.3|>=11.0,<11.1']\n",
      "\n",
      "Package vs2015_runtime conflicts for:\n",
      "pytorch -> vs2015_runtime[version='>=14.16.27012,<15.0a0']\n",
      "pytorch -> python[version='>=3.6,<3.7.0a0'] -> vs2015_runtime[version='>=14.15.26706|>=14.27.29016|>=14.16.27012']\n",
      "cudatoolkit=11 -> vs2015_runtime[version='>=14.16.27012,<15.0a0']\n",
      "python=3.7 -> vs2015_runtime[version='>=14.16.27012,<15.0a0']\n",
      "python=3.7 -> vc[version='>=14.1,<15.0a0'] -> vs2015_runtime[version='>=14.0.25123,<15.0a0|>=14.0.25420|>=14.15.26706|>=14.27.29016|>=14.16.27012']\n",
      "torchvision -> pillow[version='>=5.3.0'] -> vs2015_runtime[version='>=14.16.27012,<15.0a0']\n",
      "cudatoolkit=11 -> vc[version='>=14.1,<15.0a0'] -> vs2015_runtime[version='>=14.15.26706|>=14.27.29016|>=14.16.27012']\n",
      "\n",
      "Package zlib conflicts for:\n",
      "torchvision -> libpng -> zlib[version='>=1.2.11,<1.3.0a0']\n",
      "python=3.7 -> sqlite[version='>=3.33.0,<4.0a0'] -> zlib[version='>=1.2.11,<1.3.0a0']\n",
      "\n",
      "Package vc conflicts for:\n",
      "pytorch -> ninja -> vc[version='14.*|9.*']\n",
      "pytorch -> vc[version='>=14.1,<15.0a0']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -q pytorch torchvision cudatoolkit=11 -c pytorch-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     eng  \\\n",
       "0                                                    Hi.   \n",
       "1                                                   Run!   \n",
       "2                                                  Help!   \n",
       "3                                                  Jump!   \n",
       "4                                                  Stop!   \n",
       "...                                                  ...   \n",
       "24633  rising voices promoting a more linguistically ...   \n",
       "24634  following last year s successful campaign we i...   \n",
       "24635  during last year s challenge we also met langu...   \n",
       "24636  to take part just follow the simple steps outl...   \n",
       "24637  you will also find links to some free web base...   \n",
       "\n",
       "                                                      ar  \n",
       "0                                                مرحبًا.  \n",
       "1                                                  اركض!  \n",
       "2                                                النجدة!  \n",
       "3                                                  اقفز!  \n",
       "4                                                    قف!  \n",
       "...                                                  ...  \n",
       "24633  شاركنا تحدي ابداع ميم بلغتك الام تعزيزا للتنوع...  \n",
       "24634  استكمالا لنجاح حملة العام السابق ندعوكم للمشار...  \n",
       "24635  تعرفنا خلال تحدي العام الماضي على ابطال لغويين...  \n",
       "24636  للمشاركة في التحدي اتبع الخطوات الموضحة على ال...  \n",
       "24637  ستجد ايضا روابط لمجموعة من منصات ابداع الميم ا...  \n",
       "\n",
       "[24638 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eng</th>\n      <th>ar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>مرحبًا.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>اركض!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Help!</td>\n      <td>النجدة!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump!</td>\n      <td>اقفز!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stop!</td>\n      <td>قف!</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24633</th>\n      <td>rising voices promoting a more linguistically ...</td>\n      <td>شاركنا تحدي ابداع ميم بلغتك الام تعزيزا للتنوع...</td>\n    </tr>\n    <tr>\n      <th>24634</th>\n      <td>following last year s successful campaign we i...</td>\n      <td>استكمالا لنجاح حملة العام السابق ندعوكم للمشار...</td>\n    </tr>\n    <tr>\n      <th>24635</th>\n      <td>during last year s challenge we also met langu...</td>\n      <td>تعرفنا خلال تحدي العام الماضي على ابطال لغويين...</td>\n    </tr>\n    <tr>\n      <th>24636</th>\n      <td>to take part just follow the simple steps outl...</td>\n      <td>للمشاركة في التحدي اتبع الخطوات الموضحة على ال...</td>\n    </tr>\n    <tr>\n      <th>24637</th>\n      <td>you will also find links to some free web base...</td>\n      <td>ستجد ايضا روابط لمجموعة من منصات ابداع الميم ا...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24638 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torch.nn  import functional as F\n",
    "import torch.optim as  optim \n",
    "df = pd.read_csv(\"data/arabic_english.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Python est introuvable. Ex�cutez sans argument pour proc�der � l\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "source": [
    "# Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('في', 10114), ('من', 8806), ('على', 5213), ('ان', 2562), ('عن', 2299), ('العالمية', 2260), ('الاصوات', 2191), ('الى', 1867), ('لا', 1599), ('هذا', 1572), ('ما', 1385), ('التي', 1384), ('هذه', 1157), ('مع', 1077), ('الذي', 847), ('أن', 824), ('ذلك', 808), ('كان', 799), ('لم', 797), ('او', 797), ('الانترنت', 785), ('توم', 733), ('هل', 715), ('و', 715), ('كل', 671), ('بعد', 668), ('هو', 616), ('قبل', 580), ('تم', 572), ('موقع', 562), ('حول', 552), ('عام', 505), ('العالم', 496), ('حيث', 488), ('كما', 485), ('بين', 463), ('اكثر', 448), ('المدون', 447), ('قد', 445), ('غير', 441), ('خلال', 432), ('أنا', 432), ('إلى', 428), ('يوم', 427), ('هناك', 426), ('كانت', 424), ('بعض', 420), ('ايضا', 419), ('هي', 419), ('اي', 418)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ar import Arabic\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "df = pd.read_csv(\"data/arabic_english.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "\n",
    "'''\n",
    "First :\n",
    "python -m spacy download en_core_web_sm\n",
    "'''\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ar = Arabic()\n",
    "ar_Tokenizer = Tokenizer(ar.vocab)\n",
    "\n",
    "def engTokenizer(text):\n",
    " return  [word.text for word in spacy_eng.tokenizer(text)] \n",
    "\n",
    "def arTokenizer(sentence):\n",
    "    return  [word.text for word in \n",
    "             ar_Tokenizer(re.sub(r\"\\s+\",\" \",re.sub(r\"[\\.\\'\\\"\\n+]\",\" \",sentence)).strip())]\n",
    "\n",
    "SRC = data.Field(tokenize=engTokenizer,batch_first=False,init_token=\"<sos>\",eos_token=\"<eos>\")\n",
    "TARGET = data.Field(tokenize=arTokenizer,batch_first=False,tokenizer_language=\"ar\",init_token=\"ببدأ\",eos_token=\"نهها\")\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, src_field, target_field, is_test=False, **kwargs):\n",
    "        fields = [('eng', src_field), ('ar',target_field)]\n",
    "        samples = []\n",
    "        for i, row in df.iterrows():\n",
    "            eng = row.eng \n",
    "            ar = row.ar\n",
    "            samples.append(data.Example.fromlist([eng, ar], fields))\n",
    "\n",
    "        super().__init__(samples, fields, **kwargs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "torchdataset = TextDataset(df,SRC,TARGET)\n",
    "\n",
    "train_data, valid_data = torchdataset.split(split_ratio=0.8, random_state = random.seed(0))\n",
    "\n",
    "SRC.build_vocab(train_data,min_freq=2)\n",
    "TARGET.build_vocab(train_data,min_freq=2)\n",
    "\n",
    "print(TARGET.vocab.freqs.most_common(50))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_Embeddings = nn.Embedding(src_vocab_size,embedding_size)\n",
    "        self.src_Positional_Embeddings= nn.Embedding(max_len,embedding_size)\n",
    "        self.trg_Embeddings= nn.Embedding(trg_vocab_size,embedding_size)\n",
    "        self.trg_Positional_Embeddings= nn.Embedding(max_len,embedding_size)\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0,1) == self.src_pad_idx\n",
    "\n",
    "        return src_mask.to(device)\n",
    "\n",
    "    def forward(self,src,trg):\n",
    "        src_seq_length = src.shape\n",
    "        trg_seq_length = trg.shape\n",
    "        #adding zeros is an easy way\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .reshape(src_seq_length,1)  + torch.zeros(src_seq_length,N) \n",
    "        ).to(device)\n",
    "        \n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .reshape(trg_seq_length,1)  + torch.zeros(trg_seq_length,N) \n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "        embed_src = self.dropout(self.srcEmbeddings(x.long()) +self.srcPositionalEmbeddings(src_positions.long()))\n",
    "\n",
    "        embed_trg = self.dropout(self.trgEmbeddings(trg.long())+self.trgPositionalEmbeddings(trg_positions.long()))\n",
    "        \n",
    "        src_padding_mask = self.make_src_mask(x)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(device)\n",
    "        \n",
    "        \n",
    "        out = self.transformer(srcWords,trgWords, src_key_padding_mask=src_padding_mask,tgt_mask=trg_mask )\n",
    "        out= self.fc_out(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "source": [
    "# Training phase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of english vocabulary: 12886\nSize of arabic vocabulary: 22062\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() takes 11 positional arguments but 12 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f159c69563a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m ).to(device)\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 11 positional arguments but 12 were given"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "max_len= 250\n",
    "dropout = 0.10\n",
    "embedding_size= 512\n",
    "src_pad_idx = SRC.vocab.stoi[\"<pad>\"]\n",
    "forward_exânsion = 4\n",
    "step = 0\n",
    "\n",
    "\n",
    "\n",
    "train_iterator,valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data,valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort=False,\n",
    "    sort_within_batch=False,\n",
    "    sort_key = lambda x: len(x.SRC),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "src_vocab_size  = len(SRC.vocab)\n",
    "print(\"Size of english vocabulary:\",src_vocab_size)\n",
    "\n",
    "#No. of unique tokens in label\n",
    "trg_vocab_size =len(TARGET.vocab)\n",
    "print(\"Size of arabic vocabulary:\",trg_vocab_size)\n",
    "\n",
    "\n",
    "model = Transformer(        \n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_exânsion,\n",
    "    max_len,\n",
    "    device\n",
    ").to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4c3d9a3453d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpad_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menglish\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"<pad>\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "loss_validation_track= []\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_idx = pad_idx)\n",
    "\n",
    "if load_model: load_checkpoint(torch.load(\"my_checkpoint.pth.ptar\"),model, optimizer)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    stepLoss=[]\n",
    "    model.train() # the training mode for the model (applies dropout and batchnorms)\n",
    "    for batch  in enumerate(train_iterator):\n",
    "        input_sentence = batch.eng.to(device)\n",
    "        trg = batch.ar.to(device)\n",
    "\n",
    "        out = model(input_sentence,trg[:-1])\n",
    "\n",
    "\n",
    "        out = out.reshape(-1,trg_vocab_size)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        loss = criterion(out,trg)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        stepLoss.append(loss.item())\n",
    "        \n",
    "\n",
    "    loss_track.append(np.mean(stepLoss))\n",
    "    print(\"train crossentropy at epoch {} loss: \".format(i),np.mean(stepLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of english vocabulary: 12886\nSize of arabic vocabulary: 22062\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'max_len' and 'device'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cf4a358d0024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mnum_encoder_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mnum_decoder_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mmax_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m ).to(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'max_len' and 'device'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "fd81d4bbdfde70f601f6d77fb70c4bb77f9bd45bc2d5b01219f46a743c5582e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}