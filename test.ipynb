{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cipy mkl_fft yarl decorator zlib libsodium oauthlib protobuf freetype blinker cython pillow zeromq olefile prompt-toolkit setuptools cffi vc vs2015_runtime torchvision pytorch numba astunparse urllib3 aiohttp sqlite wincertstore markdown cachetools gast brotlipy tensorboard-plugin-wit numpy-base jpeg libprotobuf pyjwt tensorflow jupyter_client mkl_random typing-extensions pyzmq tk google-auth importlib-metadata jupyter_core numpy ninja pyasn1 jedi pyasn1-modules traitlets werkzeug libuv six opt_einsum colorama pip rsa cryptography ipykernel h5py xz wrapt multidict libtiff cudatoolkit mkl-service python-dateutil async-timeout requests-oauthlib attrs idna zstd keras-preprocessing grpcio pygments:  10%|█         | 17/167 [00:22<03:45,  1.50s/it]\n",
      "Examining conflict for pyopenssl pyjwt requests urllib3 cryptography oauthlib:  10%|█         | 17/167 [00:26<03:45,  1.50s/it]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "Examining conflict for pyopenssl pyjwt requests urllib3 cryptography oauthlib:  11%|█         | 18/167 [00:26<05:38,  2.27s/it]\n",
      "Examining conflict for tensorboard requests-oauthlib google-auth requests pip aiohttp chardet:  11%|█         | 18/167 [00:26<05:38,  2.27s/it]\n",
      "Examining conflict for google-auth-oauthlib tensorboard pyopenssl google-auth requests urllib3:  11%|█▏        | 19/167 [00:26<05:36,  2.27s/it]\n",
      "Examining conflict for google-auth-oauthlib tensorboard pyopenssl google-auth requests urllib3:  12%|█▏        | 20/167 [00:26<04:06,  1.68s/it]\n",
      "Examining conflict for requests tornado tensorflow-estimator backcall tensorboard pycparser typing_extensions wcwidth coverage chardet certifi tbb lz4-c absl-py pickleshare openssl hdf5 pysocks wheel ipython win_inet_pton google-auth-oauthlib pywin32 pyopenssl zipp parso ipython_genutils python google-pasta llvmlite termcolor keras-applications tensorflow-base pyreadline click libpng scipy mkl_fft yarl decorator zlib libsodium oauthlib protobuf freetype blinker cython pillow zeromq olefile prompt-toolkit setuptools cffi vc torchvision pytorch numba astunparse urllib3 aiohttp sqlite wincertstore markdown cachetools gast brotlipy tensorboard-plugin-wit numpy-base jpeg libprotobuf pyjwt tensorflow jupyter_client mkl_random typing-extensions pyzmq tk google-auth importlib-metadata jupyter_core numpy ninja pyasn1 jedi pyasn1-modules traitlets werkzeug libuv six opt_einsum colorama pip rsa cryptography ipykernel h5py xz wrapt multidict libtiff cudatoolkit mkl-service python-dateutil async-timeout requests-oauthlib attrs idna zstd keras-preprocessing grpcio pygments:  12%|█▏        | 20/167 [00:27<04:06,  1.68s/it]\n",
      "Examining conflict for requests tornado tensorflow-estimator backcall tensorboard pycparser typing_extensions wcwidth coverage chardet certifi tbb lz4-c absl-py pickleshare openssl hdf5 pysocks wheel ipython win_inet_pton google-auth-oauthlib pywin32 pyopenssl zipp parso ipython_genutils python google-pasta llvmlite termcolor keras-applications tensorflow-base pyreadline click libpng scipy mkl_fft yarl decorator zlib libsodium oauthlib protobuf freetype blinker cython pillow zeromq olefile prompt-toolkit setuptools cffi vc torchvision pytorch numba astunparse urllib3 aiohttp sqlite wincertstore markdown cachetools gast brotlipy tensorboard-plugin-wit numpy-base jpeg libprotobuf pyjwt tensorflow jupyter_client mkl_random typing-extensions pyzmq tk google-auth importlib-metadata jupyter_core numpy ninja pyasn1 jedi pyasn1-modules traitlets werkzeug libuv six opt_einsum colorama pip rsa cryptography ipykernel h5py xz wrapt multidict libtiff cudatoolkit mkl-service python-dateutil async-timeout requests-oauthlib attrs idna zstd keras-preprocessing grpcio pygments:  13%|█▎        | 21/167 [00:27<03:12,  1.32s/it]\n",
      "Examining conflict for markdown requests pip tornado tensorboard-plugin-wit ipykernel tensorboard jupyter_client certifi protobuf requests-oauthlib google-auth cython wheel setuptools ipython numba urllib3 grpcio pygments:  13%|█▎        | 21/167 [00:31<03:12,  1.32s/it]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "Examining conflict for markdown requests pip tornado tensorboard-plugin-wit ipykernel tensorboard jupyter_client certifi protobuf requests-oauthlib google-auth cython wheel setuptools ipython numba urllib3 grpcio pygments:  13%|█▎        | 22/167 [00:31<05:20,  2.21s/it]\n",
      "Examining conflict for pysocks requests urllib3:  13%|█▎        | 22/167 [00:32<05:20,  2.21s/it]                                                                                                                                                                              \n",
      "Examining conflict for pysocks requests urllib3:  14%|█▍        | 23/167 [00:32<04:22,  1.82s/it]\n",
      "Examining conflict for requests tornado tensorflow-estimator backcall tensorboard pycparser typing_extensions wcwidth coverage chardet certifi tbb lz4-c absl-py pickleshare openssl hdf5 pysocks wheel ipython win_inet_pton google-auth-oauthlib pywin32 pyopenssl zipp parso ipython_genutils google-pasta llvmlite termcolor keras-applications pyreadline click libpng scipy mkl_fft decorator zlib libsodium oauthlib protobuf freetype blinker cython pillow zeromq olefile setuptools cffi vc numba astunparse urllib3 sqlite wincertstore markdown cachetools gast numpy-base jpeg libprotobuf pyjwt jupyter_client typing-extensions pyzmq tk google-auth jupyter_core numpy ninja pyasn1 jedi pyasn1-modules traitlets werkzeug six opt_einsum colorama pip rsa cryptography ipykernel h5py xz wrapt libtiff mkl-service python-dateutil requests-oauthlib attrs idna zstd keras-preprocessing pygments:  14%|█▍        | 23/167 [00:32<04:22,  1.82s/it]\n",
      "Examining conflict for requests tornado tensorflow-estimator backcall tensorboard pycparser typing_extensions wcwidth coverage chardet certifi absl-py pickleshare pysocks wheel ipython win_inet_pton google-auth-oauthlib pywin32 pyopenssl zipp parso ipython_genutils python google-pasta llvmlite termcolor keras-applications tensorflow-base pyreadline click scipy mkl_fft yarl decorator oauthlib protobuf blinker cython pillow olefile prompt-toolkit setuptools cffi torchvision pytorch numba astunparse urllib3 aiohttp wincertstore markdown cachetools gast brotlipy tensorboard-plugin-wit numpy-base pyjwt tensorflow jupyter_client mkl_random typing-extensions pyzmq google-auth importlib-metadata jupyter_core numpy ninja pyasn1 jedi pyasn1-modules traitlets werkzeug six opt_einsum colorama pip rsa cryptography ipykernel h5py wrapt multidict mkl-service python-dateutil async-timeout requests-oauthlib attrs idna keras-preprocessing grpcio pygments:  14%|█▍        | 24/167 [00:34<04:20,  1.82s/it]\n",
      "Examining conflict for requests tornado tensorflow-estimator backcall tensorboard pycparser typing_extensions wcwidth coverage chardet certifi absl-py pickleshare pysocks wheel ipython win_inet_pton google-auth-oauthlib pywin32 pyopenssl zipp parso ipython_genutils python google-pasta llvmlite termcolor keras-applications tensorflow-base pyreadline click scipy mkl_fft yarl decorator oauthlib protobuf blinker cython pillow olefile prompt-toolkit setuptools cffi torchvision pytorch numba astunparse urllib3 aiohttp wincertstore markdown cachetools gast brotlipy tensorboard-plugin-wit numpy-base pyjwt tensorflow jupyter_client mkl_random typing-extensions pyzmq google-auth importlib-metadata jupyter_core numpy ninja pyasn1 jedi pyasn1-modules traitlets werkzeug six opt_einsum colorama pip rsa cryptography ipykernel h5py wrapt multidict mkl-service python-dateutil async-timeout requests-oauthlib attrs idna keras-preprocessing grpcio pygments:  15%|█▍        | 25/167 [00:34<03:53,  1.65s/it]\n",
      "Examining conflict for ipykernel jupyter_client tornado:  15%|█▍        | 25/167 [00:38<03:53,  1.65s/it]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "Examining conflict for ipykernel jupyter_client tornado:  16%|█▌        | 26/167 [00:38<05:30,  2.34s/it]\n",
      "Examining conflict for six google-pasta pip tornado tensorflow-estimator keras-applications numpy-base cryptography ipykernel tensorflow-base tensorboard scipy mkl_fft h5py pyjwt tensorflow jupyter_client mkl_random mkl-service python-dateutil oauthlib absl-py protobuf google-auth pickleshare jupyter_core numpy prompt-toolkit ipython google-auth-oauthlib pyopenssl pytorch numba keras-preprocessing astunparse zipp urllib3 traitlets grpcio:  16%|█▌        | 26/167 [00:38<05:30,  2.34s/it]\n",
      "Examining conflict for tensorboard tensorflow jupyter_client tornado ipykernel:  16%|█▌        | 27/167 [00:42<05:28,  2.34s/it]                                                                                                                                                                                                                                                                                                                                                                           \n",
      "Examining conflict for tensorboard tensorflow jupyter_client tornado ipykernel:  17%|█▋        | 28/167 [00:42<04:56,  2.13s/it]\n",
      "Examining conflict for jupyter_client ipykernel numba tornado:  17%|█▋        | 28/167 [00:42<04:56,  2.13s/it]                 \n",
      "Examining conflict for jupyter_client ipykernel numba tornado:  17%|█▋        | 29/167 [00:42<03:52,  1.69s/it]\n",
      "Examining conflict for ipython tornado:  17%|█▋        | 29/167 [00:42<03:52,  1.69s/it]                       \n",
      "Examining conflict for tensorflow-estimator tensorflow tensorflow-gpu tensorflow-base:  18%|█▊        | 30/167 [00:42<03:51,  1.69s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  19%|█▊        | 31/167 [00:43<03:49,  1.69s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  19%|█▉        | 32/167 [00:43<02:48,  1.25s/it]\n",
      "Examining conflict for tensorflow-base tensorboard libprotobuf protobuf tensorflow-estimator grpcio:  19%|█▉        | 32/167 [00:46<02:48,  1.25s/it]                                                                                                           \n",
      "Examining conflict for tensorflow-base tensorboard libprotobuf protobuf tensorflow-estimator grpcio:  20%|█▉        | 33/167 [00:46<03:42,  1.66s/it]\n",
      "Examining conflict for tensorflow-estimator tensorflow tensorflow-base gast:  20%|█▉        | 33/167 [00:47<03:42,  1.66s/it]                        \n",
      "Examining conflict for tensorflow-estimator tensorflow tensorflow-base gast:  20%|██        | 34/167 [00:47<03:17,  1.49s/it]\n",
      "Examining conflict for tensorflow-base tensorboard markdown tensorflow tensorflow-estimator:  20%|██        | 34/167 [00:48<03:17,  1.49s/it]\n",
      "Examining conflict for tensorflow-base tensorboard markdown tensorflow tensorflow-estimator:  21%|██        | 35/167 [00:48<03:04,  1.40s/it]\n",
      "Examining conflict for tensorflow-base tensorboard tensorflow tensorflow-estimator grpcio:  21%|██        | 35/167 [00:49<03:04,  1.40s/it]  \n",
      "Examining conflict for tensorflow-base tensorboard tensorflow tensorflow-estimator grpcio:  22%|██▏       | 36/167 [00:49<02:55,  1.34s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing hdf5 mkl_random tensorflow-estimator icc_rt mkl-service numpy keras-applications numpy-base:  22%|██▏       | 36/167 [00:51<02:55,  1.34s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing hdf5 mkl_random tensorflow-estimator icc_rt mkl-service numpy keras-applications numpy-base:  22%|██▏       | 37/167 [00:51<03:05,  1.43s/it]\n",
      "Examining conflict for tensorflow-estimator google-pasta tensorflow-base tensorflow:  22%|██▏       | 37/167 [00:53<03:05,  1.43s/it]                                                                                                                                       \n",
      "Examining conflict for tensorflow-estimator google-pasta tensorflow-base tensorflow:  23%|██▎       | 38/167 [00:53<03:54,  1.81s/it]\n",
      "Examining conflict for tensorflow-estimator keras-preprocessing tensorflow tensorflow-base:  23%|██▎       | 38/167 [00:55<03:54,  1.81s/it]\n",
      "Examining conflict for tensorflow-estimator keras-preprocessing tensorflow tensorflow-base:  23%|██▎       | 39/167 [00:55<03:29,  1.64s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications:  23%|██▎       | 39/167 [00:56<03:29,  1.64s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications:  24%|██▍       | 40/167 [00:56<03:11,  1.51s/it]\n",
      "Examining conflict for tensorflow-base torchvision pytorch tensorflow tensorflow-estimator cudatoolkit:  24%|██▍       | 40/167 [00:58<03:11,  1.51s/it]                                                                                             \n",
      "Examining conflict for tensorflow-base torchvision pytorch tensorflow tensorflow-estimator cudatoolkit:  25%|██▍       | 41/167 [00:58<03:49,  1.82s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl mkl_fft pytorch numba opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  25%|██▍       | 41/167 [01:00<03:49,  1.82s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl mkl_fft pytorch numba opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  25%|██▌       | 42/167 [01:00<03:36,  1.73s/it]\n",
      "Examining conflict for tensorflow-estimator tensorflow keras-applications tensorflow-base:  25%|██▌       | 42/167 [01:03<03:36,  1.73s/it]                                                                                                                         \n",
      "Examining conflict for tensorflow-estimator tensorflow keras-applications tensorflow-base:  26%|██▌       | 43/167 [01:03<04:16,  2.07s/it]\n",
      "Examining conflict for tensorflow-base tensorboard tensorflow tensorflow-estimator absl-py:  26%|██▌       | 43/167 [01:04<04:16,  2.07s/it]\n",
      "Examining conflict for tensorflow-base tensorboard tensorflow tensorflow-estimator absl-py:  26%|██▋       | 44/167 [01:04<03:43,  1.82s/it]\n",
      "Examining conflict for tensorflow-estimator termcolor tensorflow tensorflow-base:  26%|██▋       | 44/167 [01:06<03:43,  1.82s/it]          \n",
      "Examining conflict for tensorflow-estimator termcolor tensorflow tensorflow-base:  27%|██▋       | 45/167 [01:06<03:37,  1.78s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing tensorflow mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  27%|██▋       | 45/167 [01:07<03:37,  1.78s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba opt_einsum h5py keras-preprocessing tensorflow mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  28%|██▊       | 46/167 [01:07<03:15,  1.61s/it]\n",
      "Examining conflict for tensorflow-estimator tensorflow opt_einsum tensorflow-base:  28%|██▊       | 46/167 [01:10<03:15,  1.61s/it]                                                                                                                                        \n",
      "Examining conflict for tensorflow-estimator tensorflow opt_einsum tensorflow-base:  28%|██▊       | 47/167 [01:10<04:05,  2.04s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba blas opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  28%|██▊       | 47/167 [01:11<04:05,  2.04s/it]\n",
      "Examining conflict for tensorflow-base tensorboard scipy torchvision mkl_fft pytorch numba blas opt_einsum h5py keras-preprocessing mkl_random tensorflow-estimator mkl-service numpy keras-applications numpy-base:  29%|██▊       | 48/167 [01:11<03:35,  1.81s/it]\n",
      "Examining conflict for python llvmlite tensorflow-estimator tensorflow-base tensorboard libprotobuf libpng h5py tensorflow libtiff zlib protobuf freetype pillow hdf5 torchvision numba zstd sqlite grpcio:  29%|██▊       | 48/167 [01:14<03:35,  1.81s/it]         \n",
      "Examining conflict for python llvmlite tensorflow-estimator tensorflow-base tensorboard libprotobuf libpng h5py tensorflow libtiff zlib protobuf freetype pillow hdf5 torchvision numba zstd sqlite grpcio:  29%|██▉       | 49/167 [01:14<04:11,  2.13s/it]\n",
      "Examining conflict for tensorflow-base tensorboard protobuf tensorflow tensorflow-estimator grpcio:  29%|██▉       | 49/167 [01:16<04:11,  2.13s/it]                                                                                                        \n",
      "Examining conflict for tensorflow-base tensorboard protobuf tensorflow tensorflow-estimator grpcio:  30%|██▉       | 50/167 [01:16<03:56,  2.02s/it]\n",
      "Examining conflict for tensorflow-estimator tensorflow tensorflow-base:  30%|██▉       | 50/167 [01:18<03:56,  2.02s/it]                            \n"
     ]
    }
   ],
   "source": [
    "!conda install -q pytorch torchvision cudatoolkit=11 -c pytorch-nightly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torch.nn  import functional as F\n",
    "import torch.optim as  optim \n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "\n",
    "  print(\"gpu up\")\n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     eng  \\\n",
       "0                                                    Hi.   \n",
       "1                                                   Run!   \n",
       "2                                                  Help!   \n",
       "3                                                  Jump!   \n",
       "4                                                  Stop!   \n",
       "...                                                  ...   \n",
       "24633  rising voices promoting a more linguistically ...   \n",
       "24634  following last year s successful campaign we i...   \n",
       "24635  during last year s challenge we also met langu...   \n",
       "24636  to take part just follow the simple steps outl...   \n",
       "24637  you will also find links to some free web base...   \n",
       "\n",
       "                                                      ar  \n",
       "0                                                مرحبًا.  \n",
       "1                                                  اركض!  \n",
       "2                                                النجدة!  \n",
       "3                                                  اقفز!  \n",
       "4                                                    قف!  \n",
       "...                                                  ...  \n",
       "24633  شاركنا تحدي ابداع ميم بلغتك الام تعزيزا للتنوع...  \n",
       "24634  استكمالا لنجاح حملة العام السابق ندعوكم للمشار...  \n",
       "24635  تعرفنا خلال تحدي العام الماضي على ابطال لغويين...  \n",
       "24636  للمشاركة في التحدي اتبع الخطوات الموضحة على ال...  \n",
       "24637  ستجد ايضا روابط لمجموعة من منصات ابداع الميم ا...  \n",
       "\n",
       "[24638 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eng</th>\n      <th>ar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>مرحبًا.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>اركض!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Help!</td>\n      <td>النجدة!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump!</td>\n      <td>اقفز!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stop!</td>\n      <td>قف!</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24633</th>\n      <td>rising voices promoting a more linguistically ...</td>\n      <td>شاركنا تحدي ابداع ميم بلغتك الام تعزيزا للتنوع...</td>\n    </tr>\n    <tr>\n      <th>24634</th>\n      <td>following last year s successful campaign we i...</td>\n      <td>استكمالا لنجاح حملة العام السابق ندعوكم للمشار...</td>\n    </tr>\n    <tr>\n      <th>24635</th>\n      <td>during last year s challenge we also met langu...</td>\n      <td>تعرفنا خلال تحدي العام الماضي على ابطال لغويين...</td>\n    </tr>\n    <tr>\n      <th>24636</th>\n      <td>to take part just follow the simple steps outl...</td>\n      <td>للمشاركة في التحدي اتبع الخطوات الموضحة على ال...</td>\n    </tr>\n    <tr>\n      <th>24637</th>\n      <td>you will also find links to some free web base...</td>\n      <td>ستجد ايضا روابط لمجموعة من منصات ابداع الميم ا...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24638 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ara_eng.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.25.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.60.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ultrapc\\appdata\\local\\conda\\conda\\envs\\torch\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "2021-06-02 18:37:35.934691: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "source": [
    "# Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('في', 10114), ('من', 8806), ('على', 5213), ('ان', 2562), ('عن', 2299), ('العالمية', 2260), ('الاصوات', 2191), ('الى', 1867), ('لا', 1599), ('هذا', 1572), ('ما', 1385), ('التي', 1384), ('هذه', 1157), ('مع', 1077), ('الذي', 847), ('أن', 824), ('ذلك', 808), ('كان', 799), ('لم', 797), ('او', 797), ('الانترنت', 785), ('توم', 733), ('هل', 715), ('و', 715), ('كل', 671), ('بعد', 668), ('هو', 616), ('قبل', 580), ('تم', 572), ('موقع', 562), ('حول', 552), ('عام', 505), ('العالم', 496), ('حيث', 488), ('كما', 485), ('بين', 463), ('اكثر', 448), ('المدون', 447), ('قد', 445), ('غير', 441), ('خلال', 432), ('أنا', 432), ('إلى', 428), ('يوم', 427), ('هناك', 426), ('كانت', 424), ('بعض', 420), ('ايضا', 419), ('هي', 419), ('اي', 418)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ar import Arabic\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch import Tensor\n",
    "\n",
    "random.seed(0)\n",
    "df = pd.read_csv(\"data/ara_eng.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "\n",
    "\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ar = Arabic()\n",
    "ar_Tokenizer = Tokenizer(ar.vocab)\n",
    "\n",
    "def engTokenizer(text):\n",
    " return  [word.text for word in spacy_eng.tokenizer(text)] \n",
    "\n",
    "def arTokenizer(sentence):\n",
    "    return  [word.text for word in \n",
    "             ar_Tokenizer(re.sub(r\"\\s+\",\" \",re.sub(r\"[\\.\\'\\\"\\n+]\",\" \",sentence)).strip())]\n",
    "\n",
    "\n",
    "\n",
    "SRC = data.Field(tokenize=engTokenizer,batch_first=False,init_token=\"<sos>\",eos_token=\"<eos>\")\n",
    "TARGET = data.Field(tokenize=arTokenizer,batch_first=False,tokenizer_language=\"ar\",init_token=\"ببدأ\",eos_token=\"نهها\")\n",
    "\n",
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, src_field, target_field, is_test=False, **kwargs):\n",
    "        fields = [('eng', src_field), ('ar',target_field)]\n",
    "        samples = []\n",
    "        for i, row in df.iterrows():\n",
    "            eng = row.eng \n",
    "            ar = row.ar\n",
    "            samples.append(data.Example.fromlist([eng, ar], fields))\n",
    "\n",
    "        super().__init__(samples, fields, **kwargs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "        \n",
    "torchdataset = DataFrameDataset(df,SRC,TARGET)\n",
    "\n",
    "train_data, valid_data = torchdataset.split(split_ratio=0.8, random_state = random.seed(0))\n",
    "\n",
    "SRC.build_vocab(train_data,min_freq=2)\n",
    "TARGET.build_vocab(train_data,min_freq=2)  \n",
    "\n",
    "print(TARGET.vocab.freqs.most_common(50))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('في', 10114), ('من', 8806), ('على', 5213), ('ان', 2562), ('عن', 2299), ('العالمية', 2260), ('الاصوات', 2191), ('الى', 1867), ('لا', 1599), ('هذا', 1572), ('ما', 1385), ('التي', 1384), ('هذه', 1157), ('مع', 1077), ('الذي', 847), ('أن', 824), ('ذلك', 808), ('كان', 799), ('لم', 797), ('او', 797)]\n"
     ]
    }
   ],
   "source": [
    "print(TARGET.vocab.freqs.most_common(20))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('في', 10140), ('من', 8760), ('على', 5248), ('ان', 2553), ('عن', 2310), ('العالمية', 2261), ('الاصوات', 2195), ('الى', 1826), ('هذا', 1619), ('لا', 1595)]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = torchdataset.split(split_ratio=0.8, random_state = random.seed(SEED))\n",
    "\n",
    "SRC.build_vocab(train_data,min_freq=2)\n",
    "TARGET.build_vocab(train_data,min_freq=2)  \n",
    "\n",
    "print(TARGET.vocab.freqs.most_common(10))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "train_iterator,valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data,valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort=False,\n",
    "    sort_within_batch=False,\n",
    "shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslateTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        max_len,\n",
    "    ):\n",
    "        super(TranslateTransformer, self).__init__()\n",
    "        self.srcEmbeddings = nn.Embedding(src_vocab_size,embedding_size)\n",
    "        self.trgEmbeddings= nn.Embedding(trg_vocab_size,embedding_size)\n",
    "        self.srcPositionalEmbeddings= nn.Embedding(max_len,embedding_size)\n",
    "        self.trgPositionalEmbeddings= nn.Embedding(max_len,embedding_size)\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0,1) == self.src_pad_idx\n",
    "\n",
    "        return src_mask.to(device)\n",
    "\n",
    "    def forward(self,x,trg):\n",
    "        src_seq_length = x.shape[0]\n",
    "        N = x.shape[1]\n",
    "        trg_seq_length = trg.shape[0]\n",
    "        #adding zeros is an easy way\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .reshape(src_seq_length,1)  + torch.zeros(src_seq_length,N) \n",
    "        ).to(device)\n",
    "        \n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .reshape(trg_seq_length,1)  + torch.zeros(trg_seq_length,N) \n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "        srcWords = self.dropout(self.srcEmbeddings(x.long()) +self.srcPositionalEmbeddings(src_positions.long()))\n",
    "        trgWords = self.dropout(self.trgEmbeddings(trg.long())+self.trgPositionalEmbeddings(trg_positions.long()))\n",
    "        \n",
    "        src_padding_mask = self.make_src_mask(x)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(device)\n",
    "        \n",
    "        \n",
    "        out = self.transformer(srcWords,trgWords, src_key_padding_mask=src_padding_mask,tgt_mask=trg_mask )\n",
    "        out= self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size  = len(SRC.vocab)\n",
    "print(\"Size of english vocabulary:\",src_vocab_size)\n",
    "\n",
    "#No. of unique tokens in label\n",
    "trg_vocab_size =len(TARGET.vocab)\n",
    "print(\"Size of arabic vocabulary:\",trg_vocab_size)\n",
    "\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "max_len= 227\n",
    "embedding_size= 256\n",
    "src_pad_idx =SRC.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "\n",
    "model = TranslateTransformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    max_len\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0fd81d4bbdfde70f601f6d77fb70c4bb77f9bd45bc2d5b01219f46a743c5582e8",
   "display_name": "Python 3.7.10 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}